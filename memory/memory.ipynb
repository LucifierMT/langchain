{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同的memory工具\n",
    "- 利用内存实现短时记忆\n",
    "- 利用entity memory构建实体记忆\n",
    "- 利用知识图谱来构建记忆\n",
    "- 利用对话摘要来兼容内存中的长对话\n",
    "- 利用token来刷新内存缓冲区\n",
    "- 使用向量数据库实现长时记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9852\\579743416.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我是人类。\\nAI: 你好，我是AI。有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 短时记忆\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是人类。\")\n",
    "memory.chat_memory.add_ai_message(\"你好，我是AI。有什么可以帮助你的吗？\")\n",
    "\n",
    "memory.load_memory_variables({})  # 加载内存变量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9852\\1681470795.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我想吃鸡肉。\\nAI: 你好，我是AI。我帮你找找鸡肉的做法。'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现一个最近的对话窗口，超过窗口条数的对话将被删除\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "window_memory.save_context({\"input\": \"你好，我是人类。\"}, {\"output\": \"你好，我是AI。有什么可以帮助你的吗？\"})\n",
    "window_memory.save_context({\"input\": \"你好，我想吃鸡肉。\"}, {\"output\": \"你好，我是AI。我帮你找找鸡肉的做法。\"})\n",
    "\n",
    "window_memory.load_memory_variables({})  # 加载内存变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 胡八一和王胖子雪莉·杨在一起去探险，合称盗墓铁三角。\\nAI: 听起来很刺激，我也想加入他们。',\n",
       " 'entities': {'铁三角': '', '胡八一': '', '王胖子': '', '雪莉·杨': ''}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建记忆实体概念清单\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "llm = Tongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "entity_memory= ConversationEntityMemory(llm=llm)\n",
    "\n",
    "_input = {\n",
    "    \"input\": \"胡八一和王胖子雪莉·杨在一起去探险，合称盗墓铁三角。\",\n",
    "}\n",
    "\n",
    "# entity_memory.load_memory_variables(_input)  # 加载内存变量\n",
    "entity_memory.save_context(_input, \n",
    "                           {\"output\": \"听起来很刺激，我也想加入他们。\"})\n",
    "\n",
    "entity_memory.load_memory_variables({\"input\":\"铁三角是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用知识图谱构建记忆\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "kg_memory = ConversationKGMemory(llm=llm)\n",
    "\n",
    "kg_memory.save_context(\n",
    "    {\"input\": \"帮我找一下tomie。\"},\n",
    "    {\"output\": \"对不起，请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "kg_memory.save_context(\n",
    "    {\"input\": \"tomie是一个日本漫画角色。\"},\n",
    "    {\"output\": \"好的，我知道了。请问有什么具体问题吗？\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On tomie: tomie is a Japanese comic character.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_memory.load_memory_variables({\"input\": \"tomie是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomie', '日本']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_memory.get_current_entities(\"tomie最喜欢什么\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='tomie', predicate='最喜欢', object_='cosplay')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_memory.get_knowledge_triplets(\"tomie最喜欢cosplay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9852\\3800426642.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "# 长对话在内存中的处理方式：总结摘要以及token限制\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"帮我找一下tomie。\"},\n",
    "    {\"output\": \"对不起，请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"tomie是一个日本漫画角色。\"},\n",
    "    {\"output\": \"好的，我知道了。请问有什么具体问题吗？\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human asks for help in finding \"tomie.\" The AI initially does not recognize the term but then learns that tomie is a Japanese comic character. The AI then asks for clarification on the specific issue or question related to tomie.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human asks the AI to find \"tomie.\" The AI does not know what it is at first, but after the human explains that tomie is a Japanese comic character, the AI acknowledges and seeks clarification on any specific questions about tomie.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=summary_memory.chat_memory.messages\n",
    "\n",
    "# print(messages)\n",
    "\n",
    "summary_memory.predict_new_summary(messages,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ChatMessageHistory来快速获得对话摘要\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "history= ChatMessageHistory()\n",
    "history.add_user_message(\"你好，我是人类。\")\n",
    "history.add_ai_message(\"你好，我是AI。有什么可以帮助你的吗？\")\n",
    "\n",
    "# memory= ConversationSummaryMemory.from_messages(\n",
    "#     llm=llm, \n",
    "#     chat_memory=history, \n",
    "#     return_messages=True\n",
    "# )\n",
    "\n",
    "memory= ConversationSummaryMemory(\n",
    "    llm=llm, \n",
    "    chat_memory=history, \n",
    "    return_messages=True,\n",
    "    buffer=\"The human greets the AI and introduces themselves as a human. The AI responds with a greeting and offers to help the human.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI and introduces themselves as a human. The AI responds with a greeting and offers to help the human.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.buffer\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当对话持续进行且对话内容很多的时候，可以使用ConversationSummaryBufferMemory来存储对话摘要\n",
    "# 这是一种非常有用的方式，他会根据token限制来自动生成对话摘要，并且在对话内容超过token限制时，自动进行摘要\n",
    "# 在缓冲区内，会保留最近的k条对话内容\n",
    "# 比较久的对话会被删除，在删除前会进行柴窑\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "summary_buffer_memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, \n",
    "    max_token_limit=10, # 调整此值\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "summary_buffer_memory.save_context(\n",
    "    {\"input\": \"帮我找一下tomie。\"},\n",
    "    {\"output\": \"对不起，请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "summary_buffer_memory.save_context(\n",
    "    {\"input\": \"tomie是一个日本漫画角色。\"},\n",
    "    {\"output\": \"好的，我知道了。请问有什么具体问题吗？\"}\n",
    ")\n",
    "\n",
    "summary_buffer_memory.save_context(\n",
    "    {\"input\": \"他最近打算cos旺财。\"},\n",
    "    {\"output\": \"好的，我知道了。需要旺财的信息吗？\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human asks for help in finding \"tomie,\" and the AI initially does not know what it refers to. The human explains that Tomie is a Japanese comic character, and the AI acknowledges this, asking if there is a specific question about Tomie. Later, the human mentions they plan to cosplay as Wang Cai, and the AI asks if they need information about Wang Cai.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9852\\1604842732.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  token_buffer_memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# 使用token长度决定何时刷新内存\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-plus\", temperature=0, max_tokens=1000)\n",
    "\n",
    "token_buffer_memory = ConversationTokenBufferMemory(\n",
    "    llm=llm, \n",
    "    max_token_limit=100,  # 调整此值\n",
    ")\n",
    "\n",
    "token_buffer_memory.save_context(\n",
    "    {\"input\": \"帮我找一下tomie。\"},\n",
    "    {\"output\": \"对不起，请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "token_buffer_memory.save_context(\n",
    "    {\"input\": \"tomie是一个日本漫画角色。\"},\n",
    "    {\"output\": \"好的，我知道了。请问有什么具体问题吗？\"}\n",
    ")\n",
    "\n",
    "token_buffer_memory.save_context(\n",
    "    {\"input\": \"他最近打算cos旺财。\"},\n",
    "    {\"output\": \"好的，我知道了。需要旺财的信息吗？\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 他最近打算cos旺财。\\nAI: 好的，我知道了。需要旺财的信息吗？'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长时记忆的实现方式\n",
    "# 通过向量数据库来存储之前的对话内容，有的向量数据库服务还提供自动摘要等，每次对话的时候，都会从向量数据库里查询最相关的文档或历史对话\n",
    "\n",
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "longterm_memory = ConversationBufferMemory()\n",
    "\n",
    "longterm_memory.save_context(\n",
    "    {\"input\": \"帮我找一下tomie。\"},\n",
    "    {\"output\": \"对不起，请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "longterm_memory.save_context(\n",
    "    {\"input\": \"tomie是一个日本漫画角色。\"},\n",
    "    {\"output\": \"好的，我知道了。请问有什么具体问题吗？\"}\n",
    ")\n",
    "\n",
    "longterm_memory.save_context(\n",
    "    {\"input\": \"他最近打算cos旺财。\"},\n",
    "    {\"output\": \"好的，我知道了。需要旺财的信息吗？\"}\n",
    ")\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    longterm_memory.buffer.split(\"\\n\"),  # 将对话内容按行分割\n",
    "    embedding=DashScopeEmbeddings(),\n",
    ")\n",
    "\n",
    "FAISS.save_local(vectorstore, \"test_faiss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='33c79095-b447-4621-9121-73e6cd182b6f', metadata={}, page_content='Human: 帮我找一下tomie。'),\n",
       " Document(id='b493a37e-501e-4412-b98a-bfc15ece4896', metadata={}, page_content='AI: 对不起，请问什么是tomie？'),\n",
       " Document(id='f493631b-51c6-4c49-9e1f-ba17ff7bb537', metadata={}, page_content='Human: 他最近打算cos旺财。'),\n",
       " Document(id='da3165c9-030f-4989-a81c-ae48742c44dc', metadata={}, page_content='Human: tomie是一个日本漫画角色。')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAISS.load_local(\"test_faiss\", \n",
    "                 DashScopeEmbeddings(),\n",
    "                 allow_dangerous_deserialization=True\n",
    "                 ).similarity_search(\n",
    "    \"tomie最近打算cos谁？\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9520\\3040828667.py:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  vector_memory = VectorStoreRetrieverMemory(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 帮我找一下tomie。'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新打开，模拟清理内存\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "r1=FAISS.load_local(\"test_faiss\",\n",
    "                    DashScopeEmbeddings(),\n",
    "                    allow_dangerous_deserialization=True\n",
    "                    )\n",
    "r2=r1.as_retriever(\n",
    "    search_kwargs={\"k\": 1}  # 限制返回的文档数量\n",
    ")\n",
    "\n",
    "vector_memory = VectorStoreRetrieverMemory(\n",
    "    retriever=r2\n",
    ")\n",
    "\n",
    "vector_memory.load_memory_variables({\"input\": \"tomie最近打算cos谁？\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
